{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import re as re\n",
    "import seaborn as sns\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anilist GraphQL API call:\n",
    "\n",
    "The following functions will request data from https://anilist.co. If you would like to explore additional arguments and field reesponses, you can use the sandbox at https://studio.apollographql.com/sandbox/explorer, and enter https://graphql.anilist.co as the sandbox in the top right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to query anilist.co for a page from thier anime database, excluding explicit content and including only anime with the FINISHED status.\n",
    "#It also creates a useable data frame for the query.\n",
    "def anilist_query(i) -> pd.DataFrame:\n",
    "  query= '''\n",
    "  query Query($type: MediaType, $status: MediaStatus, $page: Int, $isAdult: Boolean) {\n",
    "    Page(page: $page) {\n",
    "      pageInfo {\n",
    "        currentPage\n",
    "        hasNextPage\n",
    "      }\n",
    "      media(type: $type, status: $status, isAdult: $isAdult) {\n",
    "        id\n",
    "        idMal\n",
    "        title {\n",
    "          english\n",
    "          romaji\n",
    "        }\n",
    "        type\n",
    "        format\n",
    "        status\n",
    "        seasonYear\n",
    "        source\n",
    "        genres\n",
    "        popularity\n",
    "        tags {\n",
    "          name\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  ''' \n",
    "  variables={\n",
    "    \"type\" : 'ANIME',\n",
    "    \"status\": 'FINISHED',\n",
    "    \"page\" : i,\n",
    "    \"isAdult\" : False\n",
    "  }\n",
    "  response = requests.post(url, json={'query': query,'variables': variables}) # Make the HTTP Api request\n",
    "  json = response.json()\n",
    "  df = pd.json_normalize(json['data']) #parse json for data column\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop all pages and append to data frame\n",
    "def anilist_compile(i) -> pd.DataFrame:\n",
    "    result = pd.DataFrame() #Create empty data frame.\n",
    "    while True:\n",
    "        df = anilist_query(i)\n",
    "        if df['Page.pageInfo.hasNextPage'][0] == np.True_: #test for if there is another page to query\n",
    "            df_1 = pd.json_normalize(df['Page.media']).T #flaten db for Page.media and transform\n",
    "            df_2 = pd.json_normalize(df_1[0])  #flaten db for concatinate\n",
    "            result = pd.concat([result,df_2], axis=0) #concatinate for result\n",
    "            i += 1\n",
    "            time.sleep(3) #limit request rate to complie with anilist\n",
    "        else:\n",
    "            df_1 = pd.json_normalize(df['Page.media']).T #flaten db for Page.media and transform\n",
    "            df_2 = pd.json_normalize(df_1[0]) #flaten db for concatinate\n",
    "            result = pd.concat([result,df_2], axis=0) #concatinate for result\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://graphql.anilist.co'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anilist = anilist_compile(1) #compiling from page 1 will ensure all titles are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anilist.to_csv(\"complete_anilist.csv\",index=False) # Write to csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data Collection:\n",
    "The following funcition will return a users completed anime list from https://anilist.co. You can return your own list by changing the username in mylist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query anilist.co for a defined user's anime media list with the completed status, and transform it into a useable data frame.\n",
    "def my_anilist(user_name) -> pd.DataFrame:\n",
    "    query = '''\n",
    "    query Query($userName: String, $type: MediaType, $status: MediaListStatus) {\n",
    "    MediaListCollection(userName: $userName, type: $type, status: $status) {\n",
    "        lists {\n",
    "        entries {\n",
    "            id\n",
    "            mediaId\n",
    "            media {\n",
    "            title {\n",
    "                english\n",
    "                romaji\n",
    "            }\n",
    "            format\n",
    "            }\n",
    "        }\n",
    "        name\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "        '''\n",
    "    variables={\n",
    "        \"type\" : 'ANIME',\n",
    "        \"status\": 'COMPLETED',\n",
    "        \"userName\" : user_name,\n",
    "    }\n",
    "    response = requests.post(url, json={'query': query,'variables': variables}) # Make the HTTP Api request\n",
    "    json = response.json()\n",
    "    df = pd.json_normalize(json['data']) #parse json for data column\n",
    "    df = pd.json_normalize(df['MediaListCollection.lists']) \n",
    "    df =pd.json_normalize(df[0])\n",
    "    df = pd.json_normalize(df['entries']).T #transform data frame to be readable\n",
    "    df = pd.json_normalize(df[0])\n",
    "    df = df[(df['media.format'] != \"MOVIE\") & (df['media.format'] != \"SPECIAL\") & (df['media.format'] != \"MUSIC\") & (df['media.format'] != \"TV_SHORT\")] #remove unnecesary formats\n",
    "    df['media.title.english'] = df['media.title.english'].fillna(df['media.title.romaji'])  #clean english title\n",
    "    df = df.drop(['media.title.romaji','id','media.format'],axis=1) #drop romaji title, userid, and the format of the media\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = my_anilist(\"leolion023\") #change username to import your personal list\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list.to_csv('my_anilist.csv', index=False) #Write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Anime List data for Mahou Shoujo\n",
    "\n",
    "In anilist_analysis.ipynb we do a short section comparing user popularity data from our target data set from anilist.co to the equivalent set of data from My Anime List, a site with a larger user base but a worse API experience. To accomplish this we need a short list of My Anime List ids to be able to run their API. Luckily anilist's API will also return the id for MAL. First we will import the anilist data from the csv so we don't need to run anilist_compile every time we make a query to MAL API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('complete_anilist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[(df.format != \"MOVIE\") & (df.format != \"SPECIAL\") & (df.format != \"MUSIC\") & (df.format != \"TV_SHORT\") & (df.format.notnull())] #drop irrelivant format\n",
    "df_2['title.english'] = df['title.english'].fillna(df['title.romaji']) #fill missing english titles whit romaji\n",
    "df_2 = df_2.dropna(subset=['seasonYear','idMal']) #drop missing year and mal id data\n",
    "df_2 = df_2.drop(['title.romaji','status','type','format','source','tags'],axis=1) # drop irrelivant columns\n",
    "df_2['seasonYear'] = df_2['seasonYear'].astype(int) #change float to int\n",
    "df_2.rename(columns={'title.english' : 'Title'}, inplace=True) #rename columns to make more readable\n",
    "df_2.rename(columns={'seasonYear' : 'Year'}, inplace=True) #rename column\n",
    "df_3 = df_2[(df_2['Year'] > 2004) & (df_2['Year'] <= 2024)] #narrow down search by year\n",
    "df_4 = df_3.loc[df_3['popularity'] > 5000] #narrow down search to only include titles with relevant popularity\n",
    "df_4['idMal'] = df_4['idMal'].astype(int) #change float to int\n",
    "df_4['genres'] = df_4['genres'].apply(literal_eval) #convert string to list\n",
    "df_4 = df_4.explode('genres') \n",
    "df_5 = df_4.loc[df_4['genres'] == 'Mahou Shoujo'] #narrow down to specific genre\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAL API reqires you to search each show individualy, you can do it by name, but luckily anilist will allow you to return the MAL id. Using this we are able to loop through the id's for the shows that we want. If you would like to gather data for a larger set of ids be warned that it seems to top out at around 150 shows and no reasonable amount of time between querys seems to help, so prepare for that. You will need to apply for your own CLIENT ID from the My Anime List website. I highly suggest looking through [MAL API Club](https://myanimelist.net/clubs.php?cid=13727) for pointers.\n",
    "\n",
    "**If you would like to run the MAL API code you will need to provide a file called client_id.py with your own client id from myanimelist.com (see client_id.py.example for the format)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from client_id import CLIENT_ID\n",
    "except ImportError:\n",
    "    import os\n",
    "    CLIENT_ID = os.getenv(\"CLIENT_ID\")  # Try to get it from an environment variable\n",
    "    if not CLIENT_ID:\n",
    "        raise ValueError(\"CLIENT_ID not found. Please define it in client_id.py or as an environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_mal(url):\n",
    "    response = requests.get(url, headers = {\n",
    "    'X-MAL-CLIENT-ID': client_id.CLIENT_ID\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    anime = response.json()\n",
    "    response.close()\n",
    "    df = pd.json_normalize([anime])\n",
    "    return(df)\n",
    "\n",
    "mal_list= pd.DataFrame()\n",
    "\n",
    "for i in df_5['idMal']:\n",
    "    url = 'https://api.myanimelist.net/v2/anime/' + str(i) + '?fields=rank,mean,num_list_users'\n",
    "    temp = compile_mal(url)\n",
    "    mal_list = pd.concat([mal_list,temp],axis=0)\n",
    "    time.sleep(2)\n",
    "\n",
    "mal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_list.to_csv('MAL_list.csv', index=False) #Write to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
